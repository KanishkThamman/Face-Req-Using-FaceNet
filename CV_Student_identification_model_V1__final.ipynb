{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KanishkThamman/Face-Req-Using-FaceNet/blob/main/CV_Student_identification_model_V1__final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1zazdjTsdjG"
      },
      "source": [
        "#download and import libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWPd603XKvuI"
      },
      "outputs": [],
      "source": [
        "#cloning a git repo and intalling other things. Getting a sample dataset with the req.txt...\n",
        "!pip install gdown==4.4.0\n",
        "#!git clone https://github.com/KanishkThamman/Dataset\n",
        "!curl -o 'haarcascade_frontalface_default.xml' https://raw.githubusercontent.com/GeekyShiva/OpenCV-miniProject-FaceDetection/master/haarcascade_frontalface_default.xml\n",
        "!gdown --folder https://drive.google.com/drive/folders/1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn\n",
        "!gdown --folder https://drive.google.com/drive/folders/1TX-IkAkmMq46L35r2tunTYa8FtFrWd49?usp=sharing\n",
        "!pip install -r requirements.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZvRDUSpZZyu"
      },
      "outputs": [],
      "source": [
        "#import the lib...\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaPh2nM6hRXW"
      },
      "outputs": [],
      "source": [
        "#unziping the sample dataset\n",
        "shutil.unpack_archive('Dataset/photos.zip', 'Dataset') #the sample dataset(per person one pic is only req )\n",
        "os.remove(\"Dataset/photos.zip\") #remove the zip file "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgyYsGmCo-2z"
      },
      "source": [
        "Make the  Model Identify You By Training it on your picture (optional)\n",
        "directions of use :-\n",
        "after running the code a window called photoclicker will pop up and you will have to click the Spacebar once to click your photo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YZJ-V5Uo8VN"
      },
      "outputs": [],
      "source": [
        "print(\"Your Name?\")\n",
        "name = str(input())\n",
        "cam = cv2.VideoCapture(0)\n",
        " \n",
        "cv2.namedWindow(\"Photo_Clicker\")\n",
        " \n",
        "img_counter = 0\n",
        " \n",
        "while True:\n",
        "    ret, frame = cam.read()\n",
        "    if not ret:\n",
        "        print(\"failed to grab frame\")\n",
        "        break\n",
        "    cv2.imshow(\"test\", frame)\n",
        " \n",
        "    k = cv2.waitKey(1)\n",
        "    if k%256 == 27:\n",
        "        # ESC pressed\n",
        "        print(\"Escape hit, closing...\")\n",
        "        break\n",
        "    elif k%256 == 32:\n",
        "        # SPACE pressed\n",
        "        while img_counter <= 0 :\n",
        "          img_name = \"Dataset/photos/\"+name+\".png\"\n",
        "          cv2.imwrite(img_name, frame)\n",
        "          print(\"done!!\")\n",
        "          img_counter += 1\n",
        "        else :\n",
        "          break\n",
        "cam.release()\n",
        " \n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-YeY5YdsSIm"
      },
      "source": [
        "# making the keys for the database (training the model )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xkyG0mPccUw"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "MyFaceNet = load_model('keras-facenet/model/facenet_keras.h5')\n",
        "HaarCascade = cv2.CascadeClassifier(cv2.samples.findFile('haarcascade_frontalface_default.xml'))\n",
        "# summarize input and output shape\n",
        "print(MyFaceNet.inputs)\n",
        "print(MyFaceNet.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrnvLXXOtixE"
      },
      "outputs": [],
      "source": [
        "#Makaing the key for identification of a person\n",
        "\n",
        "folder = r\"Dataset/photos/\"\n",
        "database = {}\n",
        "for filename in listdir(folder):\n",
        "\n",
        "    path = folder + filename\n",
        "    gbr1 = cv2.imread(folder +filename)\n",
        "    cascade = cv2.CascadeClassifier()\n",
        "    \n",
        "    face = HaarCascade.detectMultiScale(gbr1,1.1,4)\n",
        "    \n",
        "    if len(face)>0:\n",
        "        x1, y1, width, height = face[0]         \n",
        "    else:\n",
        "        x1, y1, width, height = 1, 1, 10, 10\n",
        "        \n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    \n",
        "    gbr = cv2.cvtColor(gbr1, cv2.COLOR_BGR2RGB)\n",
        "    gbr = Image.fromarray(gbr)                  \n",
        "    gbr_array = asarray(gbr)\n",
        "    \n",
        "    face = gbr_array[y1:y2, x1:x2]                        \n",
        "    \n",
        "    face = Image.fromarray(face)                       \n",
        "    face = face.resize((160,160))\n",
        "    face = asarray(face)\n",
        "    \n",
        "    face = face.astype('float32')\n",
        "    mean, std = face.mean(), face.std()\n",
        "    face = (face - mean) / std\n",
        "    \n",
        "    face = expand_dims(face, axis=0)\n",
        "    signature = MyFaceNet.predict(face)\n",
        "    \n",
        "    database[os.path.splitext(filename)[0]]=signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEjtrfFqu4cu"
      },
      "outputs": [],
      "source": [
        "myfile = open(\"data.pkl\", \"wb\")\n",
        "pickle.dump(database, myfile)\n",
        "myfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxhiRrzevV11"
      },
      "source": [
        "Preidiction for the person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhO8vIJ1wVMm"
      },
      "outputs": [],
      "source": [
        "myfile = open(\"data.pkl\", \"rb\")\n",
        "database = pickle.load(myfile)\n",
        "myfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Se1zldUwZPG"
      },
      "outputs": [],
      "source": [
        "\n",
        "#turing on the camara for pridiction\n",
        "cap = cv2.VideoCapture(0)\n",
        "cv2.namedWindow(\"Photo_Clicker\")\n",
        "while(True):\n",
        "\n",
        "    _, gbr1 = cap.read()\n",
        "    \n",
        "    face = HaarCascade.detectMultiScale(gbr1,1.1,4)\n",
        "    \n",
        "    if len(face)>0:\n",
        "        x1, y1, width, height = face[0]        \n",
        "    else:\n",
        "        x1, y1, width, height = 1, 1, 10, 10\n",
        "    \n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    \n",
        "    \n",
        "    gbr = cv2.cvtColor(gbr1, cv2.COLOR_BGR2RGB)\n",
        "    gbr = Image.fromarray(gbr, 'RGB')                 \n",
        "    gbr_array = asarray(gbr)\n",
        "    \n",
        "    face = gbr_array[y1:y2, x1:x2]                        \n",
        "    \n",
        "    face = Image.fromarray(face)                       \n",
        "    face = face.resize((160,160))\n",
        "    face = asarray(face)\n",
        "    \n",
        "    face = face.astype('float32')\n",
        "    mean, std = face.mean(), face.std()\n",
        "    face = (face - mean) / std\n",
        "    \n",
        "    face = expand_dims(face, axis=0)\n",
        "    signature = MyFaceNet.predict(face)\n",
        "    \n",
        "    min_dist=100\n",
        "    identity=' '\n",
        "    #compareing the keys genrated from the above video to compare with the database var created above \n",
        "    for key, value in database.items() :\n",
        "        dist = np.linalg.norm(value-signature)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = key\n",
        "            \n",
        "    cv2.putText(gbr1,identity, (100,100),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
        "    cv2.rectangle(gbr1,(x1,y1),(x2,y2), (0,255,0), 2)\n",
        "        \n",
        "    cv2.imshow('res',gbr1)\n",
        "    \n",
        "    k = cv2.waitKey(5) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "        \n",
        "cv2.destroyAllWindows()\n",
        "cap.release()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CV_Student_identification_model_V1_ final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}